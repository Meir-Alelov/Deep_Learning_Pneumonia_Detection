{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](images/director_shot.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "\n",
    "**Authors:** Student 1, Student 2, Student 3\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What are the business's pain points related to this project?\n",
    "* How did you pick the data analysis question(s) that you did?\n",
    "* Why are these questions important from a business perspective?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "***\n",
    "Questions to consider:\n",
    "* Where did the data come from, and how do they relate to the data analysis questions?\n",
    "* What do the data represent? Who is in the sample and what variables are included?\n",
    "* What is the target variable?\n",
    "* What are the properties of the variables you intend to use?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread \n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, optimizers, losses, metrics\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* Were there variables you dropped or created?\n",
    "* How did you address missing values or outliers?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/chest_xray/train/' \n",
    "test_path = '../data/chest_xray/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "idg = ImageDataGenerator(rescale=1/255, validation_split = 0.20)\n",
    "\n",
    "train_set = idg.flow_from_directory(train_path, target_size=(128, 128),\n",
    "                                    color_mode='grayscale', class_mode='binary', subset='training')\n",
    "\n",
    "validation_set = idg.flow_from_directory(train_path, target_size=(128, 128), \n",
    "                                         color_mode='grayscale', class_mode='binary', subset='validation')\n",
    "\n",
    "test_set = idg.flow_from_directory(test_path, target_size=(128, 128), \n",
    "                                         color_mode='grayscale', class_mode='binary', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_idg = ImageDataGenerator(rescale=1/255,\n",
    "                               validation_split = 0.20,\n",
    "                               rotation_range=40, \n",
    "                               width_shift_range=0.2, \n",
    "                               height_shift_range=0.2, \n",
    "                               shear_range=0.2, \n",
    "                               zoom_range=0.2, \n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "                                   \n",
    "\n",
    "train_set_aug = train_idg.flow_from_directory(train_path, target_size=(128, 128), \n",
    "                                         color_mode='grayscale', class_mode='binary', subset='training')\n",
    "\n",
    "validation_set = train_idg.flow_from_directory(train_path, target_size=(128, 128), \n",
    "                                         color_mode='grayscale', class_mode='binary', subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(history):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_conf_mat(model):\n",
    "    \n",
    "    y_pred = model.predict(test_set)\n",
    "    \n",
    "    y_hat = (y_pred > 0.5)\n",
    "                      \n",
    "    ConfusionMatrixDisplay(confusion_matrix(test_set.classes, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How did you analyze or model the data?\n",
    "* How did you iterate on your initial approach to make it better?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dummy = idg.flow_from_directory(train_path,\n",
    "                                      target_size=(128, 128),\n",
    "                                      color_mode='grayscale',\n",
    "                                      class_mode='binary',\n",
    "                                      subset='training', \n",
    "                                      batch_size=4173)\n",
    "\n",
    "test_dummy = idg.flow_from_directory(test_path, \n",
    "                                         target_size=(128, 128),\n",
    "                                         color_mode='grayscale',\n",
    "                                         class_mode='binary',\n",
    "                                         shuffle=False,\n",
    "                                         batch_size=624)\n",
    "\n",
    "train_images, train_labels = next(train_dummy)\n",
    "test_images, test_labels = next(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = DummyClassifier(strategy= 'most_frequent')\n",
    "baseline_model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meiralelov/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_accuracy = baseline_model.score(test_images, test_labels)\n",
    "print(base_accuracy)\n",
    "\n",
    "y_base_pred = baseline_model.predict(test_images)\n",
    "\n",
    "base_recall = recall_score(test_labels, y_base_pred)\n",
    "print(base_recall)\n",
    "\n",
    "plot_confusion_matrix(baseline_model, test_images, test_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple_model = models.Sequential()\n",
    "\n",
    "#simple_model.add(Flatten(input_shape = (128, 128, 1)))\n",
    "#simple_model.add(Dense(20, activation= 'sigmoid'))\n",
    "#simple_model.add(Dense(12, activation= 'sigmoid'))\n",
    "#simple_model.add(Dense(8, activation= 'sigmoid'))\n",
    "#simple_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#simple_model.compile(optimizer='SGD',\n",
    "              #loss='binary_crossentropy',\n",
    "              #metrics=['accuracy', metrics.Recall(name='recall')])\n",
    "\n",
    "#results = simple_model.fit(train_set_aug, epochs=100, batch_size=None, verbose=1, validation_data=validation_set)\n",
    "\n",
    "#simple_model.save('../data/fsm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n6/36h6cpys3pb112776ltdljwc0000gn/T/ipykernel_59729/2210165070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/fsm.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m    168\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "simple_model = models.load_model('../data/fsm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n6/36h6cpys3pb112776ltdljwc0000gn/T/ipykernel_59729/1807748418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_model' is not defined"
     ]
    }
   ],
   "source": [
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap in wrapper, do a cv score on validation. don't do evaluate until very end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n6/36h6cpys3pb112776ltdljwc0000gn/T/ipykernel_59729/3166498761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_conf_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_model' is not defined"
     ]
    }
   ],
   "source": [
    "plt_conf_mat(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What would you recommend the business do as a result of this work?\n",
    "* What are some reasons why your analysis might not fully solve the business problem?\n",
    "* What else could you do in the future to improve this project?\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
